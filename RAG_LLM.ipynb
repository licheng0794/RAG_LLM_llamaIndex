{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d635da-ed85-4203-8b7b-8109014c2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index\n",
    "pip install llama-index-core\n",
    "pip install llama-index-llms-openai\n",
    "pip install llama-index-llms-replicate\n",
    "pip install llama-index-embeddings-huggingface\n",
    "pip install llama-index-embeddings-langchain\n",
    "pip install llama-index-vector-stores-faiss\n",
    "pip install faiss-cpu\n",
    "pip install llama-index-postprocessor-flag-embedding-reranker\n",
    "pip install git+https://github.com/FlagOpen/FlagEmbedding.git # make sure git has been installed first\n",
    "# install ollama\n",
    "# https://ollama.com/download/windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07c7e5-7582-4327-adb7-2a847c25069b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# This module patches asyncio to allow nested use of asyncio.run and loop.run_until_complete.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core.extractors import (\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core import VectorStoreIndex, SimpleKeywordTableIndex, RAKEKeywordTableIndex\n",
    "import faiss\n",
    "\n",
    "\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "# import QueryBundle\n",
    "from llama_index.core import QueryBundle\n",
    "\n",
    "# import NodeWithScore\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "from llama_index.core.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever,\n",
    "    KeywordTableSimpleRetriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a88a16-0653-40b7-9830-8b08ee7a3473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a well-known American entrepreneur, venture capitalist, and author. He is best known for co-founding Y Combinator (YC), a highly successful startup accelerator program that has invested in many notable companies such as Dropbox, Reddit, Airbnb, and Stripe.\n",
      "\n",
      "Graham was born in 1970 in San Francisco, California. He dropped out of Harvard University to pursue his entrepreneurial endeavors. In the late 1990s, he co-founded several startups, including Cruise Control, which was sold to PalmSource, a subsidiary of Access Company.\n",
      "\n",
      "In 2005, Graham co-founded Y Combinator with Robert Noke and Jessica Livingston. The program's mission is to provide seed funding and mentorship to early-stage startups in exchange for equity. YC has become one of the most successful startup accelerators, having invested in over 2,000 companies since its inception.\n",
      "\n",
      "Graham is also known for his writings on entrepreneurship and venture capital. He has written several articles and essays on topics such as startup culture, fundraising, and leadership. His blog, \"Paul Graham's Blog,\" features insightful commentary on the tech industry and entrepreneurial issues.\n",
      "\n",
      "In addition to his work at YC, Graham serves as a board member or advisor to various companies and organizations. He is also an active investor in startups and has made investments through his venture capital firm, Foundation Capital.\n",
      "\n",
      "Graham's influence on the startup ecosystem and his contributions to the world of entrepreneurship have earned him recognition as one of the most successful and respected figures in the tech industry.\n"
     ]
    }
   ],
   "source": [
    "# test llama 3.2, pull llama3.2 using Ollam pull llama3.2\n",
    "llm = Ollama(model=\"llama3.2\", temperature=0.6, request_timeout=120.0) # The default temperature is 0.6. we may run llm in GPU\n",
    "resp = llm.complete(\"Who is Paul Graham?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff439ee9-d5b2-4f43-b878-e768e4cc21a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74b8d29-7c76-4807-9393-25d413e557cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set llm model \n",
    "# llama3.2 1B parameters  context length of 128K, Up to 9T tokens\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=300.0) # we may need to increase request_timeout to handle a large number of docs\n",
    "Settings.llm = llm\n",
    "\n",
    "# set embedding model, sequence length 512 for BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff90ff-d6ca-4989-972f-e58df618afbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0365c439-64cd-4f9a-ab1d-6b4e7ea824c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of docs:  3\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "directory_path = './RAG_assignment/Policy_exm'\n",
    "reader = SimpleDirectoryReader(input_dir=directory_path)\n",
    "docs = reader.load_data()\n",
    "\n",
    "print(\"the number of docs: \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4033b77-b018-4cbc-a9ba-b911aad5ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'C:\\\\Users\\\\liche\\\\Documents\\\\RAG_assignment\\\\RAG_assignment\\\\Policy_exm\\\\Policy_1.txt', 'file_name': 'Policy_1.txt', 'file_type': 'text/plain', 'file_size': 6393, 'creation_date': '2024-05-09', 'last_modified_date': '2024-12-03', 'doc_title': 'Comprehensive Data Privacy Policy'}\n"
     ]
    }
   ],
   "source": [
    "# add title for each doc and delete the first line for doc content              \n",
    "for cd in docs:\n",
    "    parts = cd.get_content().split(\"\\n\", 1)\n",
    "    metadata_additions =  {\"doc_title\": parts[0].strip().lstrip('#').strip()}\n",
    "    cd.metadata.update(metadata_additions)\n",
    "    cd.text = parts[1]\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e57c02-7917-4e42-a921-0768b7758d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any, List, Optional, Sequence\n",
    "\n",
    "from llama_index.core.callbacks.base import CallbackManager\n",
    "from llama_index.core.node_parser.interface import NodeParser\n",
    "from llama_index.core.node_parser.node_utils import build_nodes_from_splits\n",
    "from llama_index.core.schema import BaseNode, MetadataMode, TextNode\n",
    "from llama_index.core.utils import get_tqdm_iterable\n",
    "\n",
    "# create a customized section chunking node parser\n",
    "class SectionNodeParser(NodeParser):\n",
    "    \"\"\"Section node parser./using section based splitting logic.\n",
    "    Each node contains its text content and the section name leading to it.\n",
    "\n",
    "    Args:\n",
    "        include_metadata (bool): whether to include metadata in nodes\n",
    "        include_prev_next_rel (bool): whether to include prev/next relationships\n",
    "    \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def from_defaults(\n",
    "        cls,\n",
    "        include_metadata: bool = True,\n",
    "        include_prev_next_rel: bool = True,\n",
    "        callback_manager: Optional[CallbackManager] = None,\n",
    "    ) -> \"SectionNodeParser\":\n",
    "        callback_manager = callback_manager or CallbackManager([])\n",
    "        return cls(\n",
    "            include_metadata=include_metadata,\n",
    "            include_prev_next_rel=include_prev_next_rel,\n",
    "            callback_manager=callback_manager,\n",
    "        )\n",
    "\n",
    "    def get_nodes_from_node(self, node: BaseNode) -> List[TextNode]:\n",
    "        \"\"\"Get nodes from document by splitting on headers.\"\"\"\n",
    "        text = node.get_content(metadata_mode=MetadataMode.NONE)\n",
    "\n",
    "        section_pattern =  r'(\\d+(\\.\\d+)*\\.\\s[^\\n]+)'  \n",
    "        # Match sections and subsections using regex\n",
    "        matches = list(re.finditer(section_pattern, text))\n",
    "        \n",
    "        nodes = []\n",
    "        # If no matches are found, skip this document\n",
    "        if not matches:\n",
    "            print(\"No sections matched. Please check the document format or regex.\")\n",
    "            \n",
    "        # Process matches to split the document into chunks\n",
    "        for i, match in enumerate(matches):\n",
    "            # Section title\n",
    "            section_title = match.group(0).strip()\n",
    "            # Start of the next section or end of the document\n",
    "            next_start = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "            # Extract content between the current and next section\n",
    "            section_content = text[match.end():next_start].strip()\n",
    "            \n",
    "            # Combine section title and content into a single node text\n",
    "            node_text = f\"{section_title}\\n{section_content}\"\n",
    "\n",
    "            # Create a Node with the text and metadata\n",
    "            nodes.append(self._build_node_from_split(node_text, node,  metadata={\"section_title\": section_title}))\n",
    "            \n",
    "        return nodes\n",
    "\n",
    "    def _build_node_from_split(\n",
    "        self,\n",
    "        text_split: str,\n",
    "        node: BaseNode,\n",
    "        metadata: dict,\n",
    "    ) -> TextNode:\n",
    "        \"\"\"Build node from single text split.\"\"\"\n",
    "        node = build_nodes_from_splits([text_split], node, id_func=self.id_func)[0]\n",
    "\n",
    "        if self.include_metadata:\n",
    "            node.metadata = {**node.metadata, **metadata}\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _parse_nodes(\n",
    "        self,\n",
    "        nodes: Sequence[BaseNode],\n",
    "        show_progress: bool = False,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Parse nodes.\"\"\"\n",
    "        all_nodes: List[BaseNode] = []\n",
    "        nodes_with_progress = get_tqdm_iterable(nodes, show_progress, \"Parsing nodes\")\n",
    "\n",
    "        for node in nodes_with_progress:\n",
    "            nodes = self.get_nodes_from_node(node)\n",
    "            all_nodes.extend(nodes)\n",
    "\n",
    "        return all_nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87696889-80e9-4c1d-90fe-412e300d0c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create nodes and extract meta data for each node\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "transformations = [\n",
    "    # SemanticSplitterNodeParser(embed_model=OpenAIEmbedding()), # if we want to use OpenAI embedding\n",
    "    # SemanticSplitterNodeParser(embed_model=embed_model), # semantic splitter but I found it is not good for our case\n",
    "    SectionNodeParser(), \n",
    "    # TitleExtractor(nodes=5, llm=llm), # flexible to set llm here, title may not be necessary for this case because context is not long\n",
    "    QuestionsAnsweredExtractor(questions=3, llm=llm),\n",
    "    SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm),\n",
    "    KeywordExtractor(keywords=5, llm=llm)\n",
    "    # EntityExtractor(prediction_threshold=0.5, device=\"cpu\", llm=llm), # entity is not necessary for this case\n",
    "]\n",
    "\n",
    "pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "# Run the pipeline\n",
    "\n",
    "import time\n",
    "# Save timestamp\n",
    "start = time.time()\n",
    "nodes = pipeline.run(documents=docs, num_workers=1) \n",
    "\n",
    "# Save timestamp\n",
    "end = time.time()\n",
    "print(\"the time taken for node creating {} s \".format(end - start))\n",
    "print(\"the number of nodes: \", len(nodes))\n",
    "\n",
    "# if the number of docs are large, we split them into bins for preprocessing\n",
    "\n",
    "# initial_bin_size = 100\n",
    "# num_initial_bins = 21\n",
    "# total_range = len(docs)\n",
    "# # Create the first four bins with size 500 each\n",
    "# bins = [(i * initial_bin_size, (i + 1) * initial_bin_size) for i in range(num_initial_bins)]\n",
    "# # Add the remaining range as the last bin\n",
    "# bins.append((num_initial_bins * initial_bin_size, total_range))\n",
    "# nodes = []\n",
    "\n",
    "# for binRange in bins:\n",
    "#     nodes1 = pipeline.run(documents=docs[binRange[0]:binRange[-1]], num_workers=1) \n",
    "#     nodes.append(nodes1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8580b1ea-7eb9-40d2-a341-73f3138b7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the nodes with content and metadata\n",
    "# import pickle\n",
    "# with open(\"policy_nodes.pkl\", \"wb\") as file:  # 'wb' means write-binary mode\n",
    "#     pickle.dump(nodes, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833359de-a959-425f-bc17-2e2df54b1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nodes\n",
    "import pickle\n",
    "with open(\"policy_nodes.pkl\", \"rb\") as file:  # 'rb' means read-binary mode\n",
    "    nodes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfb9f2c-50f5-485f-b5e9-cac11022f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'C:\\\\Users\\\\liche\\\\Documents\\\\RAG_assignment\\\\RAG_assignment\\\\Policy_exm\\\\Policy_1.txt',\n",
       " 'file_name': 'Policy_1.txt',\n",
       " 'file_type': 'text/plain',\n",
       " 'file_size': 6393,\n",
       " 'creation_date': '2024-05-09',\n",
       " 'last_modified_date': '2024-12-03',\n",
       " 'doc_title': 'Comprehensive Data Privacy Policy',\n",
       " 'section_title': '1. Introduction**',\n",
       " 'questions_this_excerpt_can_answer': 'Based on the provided context, here are three specific questions and their potential answers:\\n\\n1. What is the specific date range during which [Company Name] was actively collecting personal data from customers, users, and employees?\\n\\nAnswer: The creation date of the policy (2024-05-09) and the last modified date (2024-12-03) imply that the company has been active in this period. However, to provide a more specific answer, we need additional information about when exactly [Company Name] started collecting personal data.\\n\\n2. Which geographic locations are covered by the scope of the policy?\\n\\nAnswer: The fact that the policy applies \"irrespective of the data collection medium or geographic location\" suggests that it covers all regions where [Company Name] operates. However, without further information about the company\\'s global presence or specific countries, we cannot pinpoint exact locations.\\n\\n3. What is the primary principle guiding [Company Name]\\'s business operations regarding personal data?\\n\\nAnswer: According to the policy, \"safeguarding the privacy and security of personal data\" is a foundational principle of [Company Name]\\'s business operations.\\n\\nAs for higher-level summaries of surrounding context, here are some possible options:\\n\\n* What other policies or guidelines does [Company Name] have in place regarding data protection and employee conduct?\\n\\t+ This question could lead to more information about the company\\'s organizational structure, compliance procedures, and potential breaches.\\n* How does this policy align with relevant laws and regulations regarding data privacy in the United States?\\n\\t+ Answering this question might require additional context on US data protection laws, such as GDPR, HIPAA, or CCPA.\\n\\nThese summaries can provide a more comprehensive understanding of [Company Name]\\'s policies and compliance standards, allowing for further exploration of their organizational practices.',\n",
       " 'section_summary': \"Based on the provided excerpt, here is a summary of the key topics and entities:\\n\\n**Key Topics:**\\n\\n1. Data Privacy Policy\\n2. Scope of the policy\\n3. Safeguarding personal data\\n4. Business operations principles\\n5. Compliance with laws and regulations (implied)\\n\\n**Entities:**\\n\\n1. [Company Name] (the organization responsible for collecting and handling personal data)\\n2. Customers\\n3. Users\\n4. Employees\\n\\nNote that the excerpt does not provide specific information about the company's global presence, geographic locations, or organizational structure, which are mentioned as potential areas of further exploration in the surrounding context.\",\n",
       " 'excerpt_keywords': 'data, privacy, policy, safeguarding, personal'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e89ce-4525-4171-8be3-60a8318cfde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05468f3f-aa76-4fd9-b224-25a8a21a806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vector store index. we can extend to other Vector DB\n",
    "d = 512 # depend on the used embedding model\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "faiss_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "vector_index = VectorStoreIndex(nodes, vector_store=faiss_store, embed_model=embed_model)\n",
    "keyword_index = SimpleKeywordTableIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca5be6-0cac-4ec3-ad55-14dbac62e8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "948cd25e-5176-4af9-afa7-b3c5a7cafaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CustomRetriever\n",
    "\n",
    "reranker =  SentenceTransformerRerank(model=\"BAAI/bge-reranker-large\", top_n=5)\n",
    "\n",
    "# define a customized Retriever which can switch between vector search and hybrid search with different reranker model \n",
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both Vector/hybrid search and Reranking\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_retriever: VectorIndexRetriever,\n",
    "        keyword_retriever: KeywordTableSimpleRetriever,\n",
    "        reranker: reranker,\n",
    "        Mode: str = \"Vector\" # \"HybridAND\", \"HybridOR\", \"Vector\"\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._keyword_retriever = keyword_retriever\n",
    "        if Mode not in (\"HybridAND\", \"HybridOR\", \"Vector\"):\n",
    "            raise ValueError(\"Invalid Hybrid mode.\")\n",
    "        self._Mode = Mode\n",
    "        self._reranker = reranker\n",
    "        super().__init__()\n",
    "   \n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        keyword_nodes = self._keyword_retriever.retrieve(query_bundle) # we can control the number of keywords here\n",
    "\n",
    "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
    "        keyword_ids = {n.node.node_id for n in keyword_nodes}\n",
    "\n",
    "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
    "        combined_dict.update({n.node.node_id: n for n in keyword_nodes})\n",
    "        \n",
    "        if self._Mode == \"HybridAND\":\n",
    "            retrieve_ids = vector_ids.intersection(keyword_ids) # and. We use 'and' for our case\n",
    "            if len(retrieve_ids) ==0:\n",
    "                retrieve_ids = vector_ids\n",
    "        elif self._Mode == \"HybridOR\":\n",
    "             retrieve_ids = vector_ids.union(keyword_ids) # or\n",
    "        else: # vector search\n",
    "             retrieve_ids = vector_ids\n",
    "        \n",
    "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
    "        \n",
    "        if self._reranker is not None:\n",
    "            retrieve_nodes = self._reranker.postprocess_nodes(retrieve_nodes, query_bundle)\n",
    "        \n",
    "        return retrieve_nodes\n",
    "\n",
    "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5) # make similarity_top_k a bit higher can include a broad knowledge\n",
    "keyword_retriever = KeywordTableSimpleRetriever (index=keyword_index) \n",
    "# keyword_retriever = KeywordTableLLMRetriever(index=keyword_index) \n",
    "\n",
    "# hybrid search with the intersection between vectors and keywords search with reranker\n",
    "hybrid_retriever_reranker_AND = CustomRetriever(vector_retriever, keyword_retriever, reranker, 'HybridAND') \n",
    "# hybrid search with the union of vectors and keywords search without reranker\n",
    "hybrid_retriever_None_OR = CustomRetriever(vector_retriever, keyword_retriever, None, 'HybridOR') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b19984c3-18a6-4930-876e-292a27afcbe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [05:43<00:00, 12.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# Retrieval evluation to select a retriever and embedding model\n",
    "# step 1: generate questions based on the context\n",
    "# step 2: use the questions as the queries, check whether the relevant context included in the retrieved nodes and calc metrics \n",
    "\n",
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs\n",
    ")\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "generate_qa_prompt = \"\"\"\\\n",
    "            Context information is below.\n",
    "            \n",
    "            ---------------------\n",
    "            {context_str}\n",
    "            ---------------------\n",
    "            \n",
    "            Given the context information and no prior knowledge.\n",
    "            generate only questions based on the below query.\n",
    "            \n",
    "            You are a Teacher/ Professor. Your task is to setup \\\n",
    "            {num_questions_per_chunk} questions for an upcoming \\\n",
    "            quiz/examination. The questions should be diverse in nature \\\n",
    "            across the document. Restrict the questions to the \\\n",
    "            context information provided. Do not ask the questions like \"Here are {num_questions_per_chunk} questions based on the context information:\"\\\n",
    "            and do not include any anwer.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "qa_dataset = generate_question_context_pairs(\n",
    "    nodes,\n",
    "    llm=llm,\n",
    "    num_questions_per_chunk=3, #  generating questions when <5, generating answers and questions when >5\n",
    "    qa_generate_prompt_tmpl = generate_qa_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41073a9c-11d4-4766-85a2-ce2891cf8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"qa_dataset.pkl\", \"wb\") as file:  # 'wb' means write-binary mode\n",
    "#     pickle.dump(qa_dataset, file)\n",
    "with open(\"qa_dataset.pkl\", \"rb\") as file:  # 'rb' means read-binary mode\n",
    "    qa_dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147043eb-f24a-420c-b40e-7de38fdda7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of questions generated:  81\n"
     ]
    }
   ],
   "source": [
    "# show the generated questions\n",
    "print (\"the number of questions generated: \", len(qa_dataset.queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec681f86-d2ee-406c-ae1d-eb1c6539341c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'16750bf6-6cae-494a-853a-35e257834384': \"What is the foundational principle of [Company Name]'s business operations regarding personal data?\",\n",
       " 'b9999098-2cdf-4e41-a3d9-9d61bcc9f58a': \"According to what does this Data Privacy Policy aim to transparently communicate about [Company Name]'s practices?\",\n",
       " 'e4271bfd-1644-4ed0-a44d-3892a3b844fd': 'Who does this policy apply universally to, regardless of their location?',\n",
       " '2c843939-3af9-4da0-b2b4-fb0fb7207413': 'What types of data are collected when individuals access and utilize a service, according to the given data collection practices?',\n",
       " '0cd7d2e2-1b28-449e-9d0f-9228251bfcd8': 'A) Personal Identification Information',\n",
       " '53d033fc-f834-4557-91e6-b12e6dd400e9': 'B) Usage Data',\n",
       " 'cfc0d5d8-7fef-4581-a77d-d9d0e7a77b60': 'Where are data storage locations chosen for their stringent security standards and data protection compliance?',\n",
       " '7dd8d3b7-a13c-4cc5-b27b-5d8d30a8db85': 'What is the purpose of implementing role-based access controls (RBAC) to secure sensitive data?',\n",
       " '0a8d80d6-fffa-4f29-9561-4a09eae6078d': \"According to the company's data retention policy, what happens to data after its stated purposes have been fulfilled?\",\n",
       " 'b4ce74cd-dea0-4f64-854a-45ba04697127': 'How does the organization use data to improve its existing services and develop new offerings?',\n",
       " 'c3be0afb-4687-49b5-91e2-eecf24a17638': 'What mechanisms are in place to ensure fairness, accuracy, and accountability in automated decision-making processes?',\n",
       " '70aade7e-a797-42f0-9826-9af2a8a8b2df': 'How does the use of data enhance the ability to offer personalized services and improve overall user satisfaction?',\n",
       " '20c5a7ca-57bf-45bc-a508-45d7db6dde7d': 'What are some circumstances under which data is shared with trusted partners?',\n",
       " 'bc2cb3e1-91ab-4e78-b376-c0902eb5d1c4': \"How does a user obtain control over their personal information, according to the document's guidelines?\",\n",
       " '8b32ecf4-afe8-4f2b-b3c8-7c5b9cd33e3e': 'Why are legal and compliance requirements mentioned as a reason for disclosing data?',\n",
       " 'ed58b446-158a-4eef-b762-ea8c7e21fe30': 'What is the primary right granted to users regarding their data, as per the context information?',\n",
       " '1da87139-06a0-48d3-9c0d-c320da45b895': 'Under what conditions can a user request the deletion of their personal data from your system?',\n",
       " '02374114-4b7a-4024-9377-e2bd5bd95f2d': \"How does the concept of 'Data Portability' facilitate for users in terms of accessing and reusing their personal data?\",\n",
       " 'db96790e-742b-4b91-bbcc-2f01b593ecb2': 'What type of regulations does your organization adhere to, specifically mentioning GDPR and CCPA?',\n",
       " '185e4529-6fca-431d-94a9-79d4ad048d0f': 'How does your organization ensure compliance with international laws and regulations in all its practices?',\n",
       " '7ba4f2ee-1591-446b-955c-87fe130b9bd0': 'What happens when data privacy concerns or policy violations are reported to your organization?',\n",
       " 'd26d04c0-59a9-4e01-bcda-7644504bd6c0': 'What is the name of the contact email used for privacy concerns regarding the Data Privacy Policy?',\n",
       " 'd3113edf-887c-41c4-a09a-29359886ae20': 'Who should be contacted for further inquiries or concerns related to the Data Privacy Policy?',\n",
       " 'c7277dfb-be09-4ab8-a5ee-6e72821c87ba': 'How can users get in touch with the individual responsible for handling data protection queries?',\n",
       " '6c3eafa8-f428-4eac-8176-cf39e2f008b7': \"What is the primary focus of [Company Name]'s approach to user trust?\",\n",
       " 'bca4f7a1-5db9-4068-a395-1e8d4a6f884d': 'How often should users review their personal data privacy policy according to [Company Name]?',\n",
       " 'ad28bea5-6ac1-4638-bee8-7ebe23a9c5b9': \"What are [Company Name]'s highest standards for maintaining user data privacy and security?\",\n",
       " 'cad8e930-7914-4cd7-9fe6-cc2c083fbde1': \"What is the primary focus of [Company Name]'s AI policy?\",\n",
       " '54c4c9a0-1a6a-4ca7-8245-bc075902c94b': 'How does [Company Name] define the use of artificial intelligence that respects human dignity and rights?',\n",
       " 'cab28ea7-941e-47d8-a187-3d0120f541f2': 'What responsibility does a leader in AI innovation, like [Company Name], recognize itself to be held?',\n",
       " '03921e61-4dc3-4e73-88d9-b4f7d2e45874': 'What is the scope of this AI policy, and what types of activities does it cover?',\n",
       " '8ec59ae8-8ed7-452d-b92e-fa52220d0942': \"Who is affected by this AI policy across [Company Name]'s global operations?\",\n",
       " '97ca3266-3412-488e-aa86-48fc2510d710': 'How does this policy apply to business partners involved with AI technologies?',\n",
       " '41102771-fea2-4c22-97c5-59150751efbc': 'What is the primary goal of an AI system that is capable of learning from data and experience?',\n",
       " '8ee8ee43-bcac-4f57-8e8e-1141053263f2': 'In what aspect do fairness, transparency, non-discrimination, and accountability relate to the functioning of AI systems?',\n",
       " 'f3928642-ea5e-4efd-a5c6-561e19a4e1a4': \"Can you think of a situation in which an AI system's lack of transparency could lead to unfair outcomes?\",\n",
       " '2ff37731-cafb-4f65-8b82-9a7d407b5b95': 'What framework will be developed to monitor biases in AI systems, and how often will it be reviewed?',\n",
       " '277c43c5-1e43-45d6-a08c-e98c8c951cfa': 'In what ways can users query AI decisions and receive explanations for their outputs?',\n",
       " '5540b299-244d-44de-a9fc-08d46519f363': 'Who or what entity is responsible for evaluating and approving new AI projects to ensure compliance with non-discrimination standards?',\n",
       " '2ca354b6-7582-49a0-a873-2db4635d29e1': 'What role will the AI Ethics Board play in enhancing governance, specifically regarding periodic ethical reviews of existing AI systems?',\n",
       " 'f5012b88-5d97-4514-aec7-f33065fcd883': 'How does predictive modeling fit into the risk assessment process to forecast potential ethical issues in AI system development?',\n",
       " '812bdcec-2f78-493d-9ea8-9b07e7d11a50': 'What type of training program is being established to promote an ethical AI culture within the company?',\n",
       " '42bb8e72-7b3c-4451-b503-2a29881da1f3': 'What procedures does this ethics policy outline for handling violations, including specific disciplinary actions?',\n",
       " '6f91bafe-d8c5-4380-b22c-eac66be90e17': 'How does the severity of a breach determine the level of disciplinary action taken in response to a violation?',\n",
       " '675b9bfa-ed1d-443c-bc88-ce8e4d4ca744': 'What is the most severe disciplinary action that can be taken against an individual who violates this ethics policy?',\n",
       " '8d5f4f0d-fc14-44f6-b201-e2298360b5f8': 'How often will this AI Ethics Policy undergo revisions to stay updated with technological advancements, legal changes, and evolving societal norms?',\n",
       " '2bfb0b70-8032-4ba6-bce6-f7d0a2113008': 'What is the primary goal of adhering to the expanded guidelines outlined in the AI Ethics Policy?',\n",
       " '9c024b22-f380-4411-b9a5-6b64008b9764': 'In what way does the implementation of this policy aim to foster trust and collaboration among all stakeholders involved?',\n",
       " 'c81335a4-5f25-4bdf-aa6b-bc994640f7e2': 'What is the primary purpose of the Model Governance Policy?',\n",
       " '2f0d001f-ff32-4a20-80a5-bbf079cae8d3': 'Which stakeholders are required to understand and implement the guidelines set forth in this policy?',\n",
       " '9506a1fd-5737-4459-9012-c35fc0b22f5e': 'How does the scope of the Model Governance Policy cover AI models at various stages of their lifecycle?',\n",
       " 'bfe3d521-e129-4ec0-9c36-be36264b85d0': \"What is the company's stance on developing AI technologies that respect privacy?\",\n",
       " 'f235772f-50f8-4d42-b806-8fb99180eccb': 'How can AI technologies be made fair, transparent, and accountable?',\n",
       " '90bc393a-ee9c-4afe-955f-fdcd82a0adb7': 'What does the policy statement mean by ensuring non-discrimination in AI endeavors?',\n",
       " '45a9c301-81bb-4dfd-88c6-30a5f9f3f3b2': 'What is the primary function of an AI Model, according to its definition?',\n",
       " '6aabc5e3-cdec-41c8-9c6c-9d1572c68ae4': \"In what context does the term 'Deployment' primarily come into play?\",\n",
       " 'eb50748e-3ec2-4dee-8174-e23e4be6a196': 'How does the process of Monitoring relate to ensuring that AI models operate within predefined norms and ethics?',\n",
       " '4f61b0ed-434a-4e46-be7f-26f066b08228': 'What is the primary role of the Model Owners within the governance structure?',\n",
       " '7531bf4b-8010-4dd5-a979-3830bd8fef85': 'How does decision-making authority for AI model governance decisions get escalated in terms of criticality and impact?',\n",
       " '7767cb85-5f22-4cda-9df7-688d8f2ca036': 'Who are responsible for ensuring adherence to AI governance policy and overseeing all AI initiatives?',\n",
       " '8e69e76a-7054-41bd-ac2b-7cae5c0c5649': 'What structured process should AI model development follow?',\n",
       " '33df785d-86e6-4673-81d2-276d27386998': 'Which aspects of AI model design should be considered during the design phase?',\n",
       " 'a3bcdeb8-c25c-4476-aed5-1bb8d8f842c9': 'Why is documentation of all test results mandatory for models?',\n",
       " '18af7359-5722-426f-a2a7-84811e6633b4': 'What is the purpose of reviewing AI models by the AI Governance Board before deployment?',\n",
       " '9ffab805-5878-4d41-b01f-11b4bf37b0de': 'How does post-deployment AI model monitoring differ from testing performed during review?',\n",
       " '2dd25c38-7715-4f62-9dcf-fd95299e6a56': 'What tools or strategies are used to track performance after an AI model has been deployed?',\n",
       " 'dc4e115e-1abd-4408-8b11-c600241e5063': 'What is the purpose of continuous performance evaluation for AI models?',\n",
       " '4db84d5f-e83f-42db-b827-cfabb7944342': 'How often should models be updated and maintained to ensure relevance and compliance with regulatory requirements?',\n",
       " '807e0ab4-bc10-4bf6-a93b-bb898c4c5393': \"What are some key factors that AI models' performance can degrade or deviate from, necessitating regular monitoring?\",\n",
       " '80c3b0d2-213e-4da1-a39b-ecbbc66329f1': 'What is the importance of adhering to local, national, and international AI regulations for model governance activities?',\n",
       " 'bddf8ed9-95d0-4862-b0ee-415cf469aaf4': \"How does the company's reporting system contribute to transparency in AI governance activities?\",\n",
       " '05c8b23f-4dc0-47e2-9fec-331158884dfd': 'What types of regulatory bodies require access to the detailed reports maintained by the company?',\n",
       " 'a7aa7771-eab9-48c2-bb54-29a20542f1f0': 'What is the primary purpose of conducting a risk assessment for AI models?',\n",
       " '0431c1bd-dc5d-4472-bfbf-15e48d882da4': 'How can additional training be used as a mitigation strategy to address identified risks in AI development?',\n",
       " '742ff646-0af1-4fba-a7f7-b7c90eb31ba7': 'Why are regular awareness campaigns considered necessary for all staff involved in AI management?',\n",
       " '95221ca6-0d78-440c-951b-352993524689': 'How often is this policy reviewed, and by whom?',\n",
       " '05eb923e-4d85-4ec7-b915-bb75f450b4df': 'What is the process for updating this policy, including documentation requirements?',\n",
       " '5557a49e-916b-48cc-87c1-f5188c7b36f0': 'Who must be informed of updates to this policy before implementation?',\n",
       " 'def37637-2db7-4234-b604-6dc8cb57735a': 'What type of documents does the policy refer to as being listed in the Appendix?',\n",
       " '3a36b40d-2cd3-4b2c-ba44-8b934945c005': 'Where can one find contact information for clarifying aspects of this policy?',\n",
       " '1232300d-2a2d-4e9f-b653-3d476990914a': 'According to the document, what is the purpose of ensuring AI-related activities are conducted responsibly and ethically?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e8932-cb23-43f4-a9bc-c05333810ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list the options for embedding model, rerank model and search method\n",
    "\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "EMBEDDINGS = {\n",
    "    \"bge-small\": HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5'), \n",
    "    \"MiniLM-L6-v2\": HuggingFaceEmbedding(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "}\n",
    "RERANKERS = {\n",
    "    \"WithoutReranker\": None,\n",
    "    \"bge-reranker-base\": SentenceTransformerRerank(model=\"BAAI/bge-reranker-base\", top_n=5),\n",
    "    \"bge-reranker-large\": SentenceTransformerRerank(model=\"BAAI/bge-reranker-large\", top_n=5)\n",
    "}\n",
    "SEARCHERS = {\n",
    "    \"Vector Search\": \"Vector\", # vector search\n",
    "    \"Hybrid Search AND\": \"HybridAND\", # hybrid search using the interaction between vector and keyword\n",
    "    \"Hybrid Search OR\": \"HybridOR\" # hybrid search using the union of vector and keyword\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e731837b-7ebb-40e0-bc70-c7ddd8ddd471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the embedding model:  bge-small\n",
      "None\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000168269B1A30> model='BAAI/bge-reranker-base' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000016847014DD0> model='BAAI/bge-reranker-large' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "None\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000168269B1A30> model='BAAI/bge-reranker-base' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000016847014DD0> model='BAAI/bge-reranker-large' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "None\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000168269B1A30> model='BAAI/bge-reranker-base' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000016847014DD0> model='BAAI/bge-reranker-large' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "the embedding model:  MiniLM-L6-v2\n",
      "None\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000168269B1A30> model='BAAI/bge-reranker-base' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000016847014DD0> model='BAAI/bge-reranker-large' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "None\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000168269B1A30> model='BAAI/bge-reranker-base' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000016847014DD0> model='BAAI/bge-reranker-large' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "None\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000168269B1A30> model='BAAI/bge-reranker-base' top_n=5 device='cpu' keep_retrieval_score=False\n",
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000016847014DD0> model='BAAI/bge-reranker-large' top_n=5 device='cpu' keep_retrieval_score=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Hybrid Search OR/bge-reranker-large</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.699375</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.699375</td>\n",
       "      <td>0.254175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Hybrid Search OR/bge-reranker-base</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.721042</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.721042</td>\n",
       "      <td>0.260963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Hybrid Search OR/WithoutReranker</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.266585</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.266585</td>\n",
       "      <td>0.094650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Hybrid Search AND/bge-reranker-large</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.218542</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.285409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Hybrid Search AND/bge-reranker-base</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>0.218542</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>0.280395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Hybrid Search AND/WithoutReranker</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.218542</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.216403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Vector Search/bge-reranker-large</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.246092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Vector Search/bge-reranker-base</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.685417</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.685417</td>\n",
       "      <td>0.243518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MiniLM-L6-v2/Vector Search/WithoutReranker</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.159993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Hybrid Search OR/bge-reranker-large</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0.261383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Hybrid Search OR/bge-reranker-base</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.264891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Hybrid Search OR/WithoutReranker</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>0.099740</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>0.092329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Hybrid Search AND/bge-reranker-large</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.227708</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.288293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Hybrid Search AND/bge-reranker-base</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.619792</td>\n",
       "      <td>0.227708</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.619792</td>\n",
       "      <td>0.286156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Hybrid Search AND/WithoutReranker</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.395625</td>\n",
       "      <td>0.227708</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.395625</td>\n",
       "      <td>0.221587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Vector Search/bge-reranker-large</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.712917</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.712917</td>\n",
       "      <td>0.255724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Vector Search/bge-reranker-base</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.254639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-small/Vector Search/WithoutReranker</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.397083</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.397083</td>\n",
       "      <td>0.174224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          retrievers  hit_rate       mrr  \\\n",
       "0   MiniLM-L6-v2/Hybrid Search OR/bge-reranker-large    0.9000  0.699375   \n",
       "0    MiniLM-L6-v2/Hybrid Search OR/bge-reranker-base    0.9125  0.721042   \n",
       "0      MiniLM-L6-v2/Hybrid Search OR/WithoutReranker    0.9500  0.266585   \n",
       "0  MiniLM-L6-v2/Hybrid Search AND/bge-reranker-large    0.7375  0.639583   \n",
       "0   MiniLM-L6-v2/Hybrid Search AND/bge-reranker-base    0.7375  0.627083   \n",
       "0     MiniLM-L6-v2/Hybrid Search AND/WithoutReranker    0.7375  0.386667   \n",
       "0      MiniLM-L6-v2/Vector Search/bge-reranker-large    0.8125  0.695833   \n",
       "0       MiniLM-L6-v2/Vector Search/bge-reranker-base    0.8125  0.685417   \n",
       "0         MiniLM-L6-v2/Vector Search/WithoutReranker    0.8125  0.362292   \n",
       "0      bge-small/Hybrid Search OR/bge-reranker-large    0.9250  0.719167   \n",
       "0       bge-small/Hybrid Search OR/bge-reranker-base    0.9250  0.731667   \n",
       "0         bge-small/Hybrid Search OR/WithoutReranker    0.9875  0.247070   \n",
       "0     bge-small/Hybrid Search AND/bge-reranker-large    0.7625  0.627500   \n",
       "0      bge-small/Hybrid Search AND/bge-reranker-base    0.7625  0.619792   \n",
       "0        bge-small/Hybrid Search AND/WithoutReranker    0.7625  0.395625   \n",
       "0         bge-small/Vector Search/bge-reranker-large    0.8750  0.712917   \n",
       "0          bge-small/Vector Search/bge-reranker-base    0.8750  0.708333   \n",
       "0            bge-small/Vector Search/WithoutReranker    0.8750  0.397083   \n",
       "\n",
       "   precision  recall        ap      ndcg  \n",
       "0   0.180000  0.9000  0.699375  0.254175  \n",
       "0   0.182500  0.9125  0.721042  0.260963  \n",
       "0   0.096297  0.9500  0.266585  0.094650  \n",
       "0   0.218542  0.7375  0.639583  0.285409  \n",
       "0   0.218542  0.7375  0.627083  0.280395  \n",
       "0   0.218542  0.7375  0.386667  0.216403  \n",
       "0   0.162500  0.8125  0.695833  0.246092  \n",
       "0   0.162500  0.8125  0.685417  0.243518  \n",
       "0   0.162500  0.8125  0.362292  0.159993  \n",
       "0   0.185000  0.9250  0.719167  0.261383  \n",
       "0   0.185000  0.9250  0.731667  0.264891  \n",
       "0   0.099740  0.9875  0.247070  0.092329  \n",
       "0   0.227708  0.7625  0.627500  0.288293  \n",
       "0   0.227708  0.7625  0.619792  0.286156  \n",
       "0   0.227708  0.7625  0.395625  0.221587  \n",
       "0   0.175000  0.8750  0.712917  0.255724  \n",
       "0   0.175000  0.8750  0.708333  0.254639  \n",
       "0   0.175000  0.8750  0.397083  0.174224  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run retrieval evaluation\n",
    "\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]\n",
    "metric_df = []\n",
    "for embedKey in EMBEDDINGS.keys(): # loop all embedding models\n",
    "    print(\"the embedding model: \", embedKey)\n",
    "\n",
    "    if embedKey == \"bge-small\":\n",
    "        d = 512\n",
    "    else:\n",
    "        d = 384 # all-MiniLM-L6-v2\n",
    "    faiss_index = faiss.IndexFlatL2(d)\n",
    "    faiss_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    vector_index = VectorStoreIndex(nodes, vector_store=faiss_store, embed_model=EMBEDDINGS[embedKey])\n",
    "    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5)\n",
    "    \n",
    "    Settings.embed_model = EMBEDDINGS[embedKey] # change the global setting\n",
    "    for searchKey in SEARCHERS.keys(): # loop all search methods\n",
    "        for rerankerKey in RERANKERS.keys(): # loop all reranker methods\n",
    "            print(RERANKERS[rerankerKey])\n",
    "            Retriever = CustomRetriever(vector_retriever, keyword_retriever, RERANKERS[rerankerKey], SEARCHERS[searchKey])\n",
    "            retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "                metrics, retriever=Retriever\n",
    "            )\n",
    "            eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)\n",
    "\n",
    "            metric_dicts = []\n",
    "            for eval_result in eval_results:\n",
    "                metric_dict = eval_result.metric_vals_dict\n",
    "                metric_dicts.append(metric_dict)\n",
    "            full_df = pd.DataFrame(metric_dicts)\n",
    "            columns = {\n",
    "                \"retrievers\": embedKey + '/' + searchKey + '/' + rerankerKey,\n",
    "                **{k: [full_df[k].mean()] for k in metrics},\n",
    "            }\n",
    "            if  len(metric_df)==0: \n",
    "                metric_df = pd.DataFrame(columns)\n",
    "            else: \n",
    "                metric_df = pd.concat([pd.DataFrame(columns), metric_df])\n",
    "metric_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16d94de3-095c-4059-95ab-de3dd9423a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# based on the retrieval evaluation above,\n",
    "# I chose the hybrid OR search method, the bge-small embedding model and the bge-reranker-large reranker\n",
    "\n",
    "# set embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5')\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# set retriever\n",
    "d= 512\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "faiss_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "vector_index = VectorStoreIndex(nodes, vector_store=faiss_store, embed_model=embed_model)\n",
    "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5)\n",
    "keyword_retriever = KeywordTableSimpleRetriever (index=keyword_index) \n",
    "reranker = SentenceTransformerRerank(model=\"BAAI/bge-reranker-large\", top_n=5)\n",
    "hybrid_retriever_reranker_OR = CustomRetriever(vector_retriever, keyword_retriever, reranker, 'HybridOR') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5429e88f-c92d-45b9-8ce6-9f5fc5c95c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    \"Do not add any information that is not explicitly present in the retrieved content. \"\n",
    "    \"If the information is not available, respond with, \\\"The provided documents do not contain this information.\\\"\\n\"\n",
    "    \"Do not try to make up an answer.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "79774356-e321-4de9-8d14-83be10f43bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context information, the AI Ethics Policy is a document that outlines the guiding principles and procedures for the governance of artificial intelligence (AI) model development, deployment, and monitoring within the company.\n",
      "\n",
      "To follow the AI Ethics policy, you are expected to:\n",
      "\n",
      "1. Understand and implement the guidelines set forth in this policy.\n",
      "2. Collaborate with interdisciplinary teams, including ethicists and sociologists, to understand and address the nuances of fairness in diverse cultural and social contexts (as mentioned in Principle 4.1 Fairness).\n",
      "3. Enhance transparency by developing interfaces that allow users to query AI decisions and receive explanations in understandable terms (as mentioned in Principle 4.2 Transparency).\n",
      "4. Document all AI systems' decision-making processes and methodologies, ensuring that this documentation is accessible to all relevant stakeholders and regularly updated (as mentioned in Principle 4.2 Transparency).\n",
      "5. Establish a rigorous protocol for the continuous auditing of AI algorithms and training data sets to detect and correct biases that could lead to discriminatory outcomes (as mentioned in Principle 4.3 Non-Discrimination).\n",
      "6. Create an independent review committee to evaluate and approve all new AI projects for compliance with non-discrimination standards before they are deployed (as mentioned in Principle 4.3 Non-Discrimination).\n",
      "7. Implement a standardized AI incident reporting system, which ensures all potential issues are logged, investigated, and addressed promptly (as mentioned in Principle 4.4 Accountability).\n",
      "8. Define clear escalation paths for ethical concerns related to AI, including a direct line to the AI Ethics Board (as mentioned in Principle 4.4 Accountability).\n"
     ]
    }
   ],
   "source": [
    "# create a RAG Query engine\n",
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "import os\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "\n",
    "class Myresponse:\n",
    "    def __init__(self, field1, field2):\n",
    "        self.response = field1\n",
    "        self.source_nodes = field2\n",
    "\n",
    "class RAGStringQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: Ollama\n",
    "    qa_prompt: PromptTemplate\n",
    "    \n",
    "    def custom_query(self, query_str: str):\n",
    "        retrieval_nodes = self.retriever.retrieve(query_str) # retrieved nodes\n",
    "        query_bundle = QueryBundle(query_str)\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content() for n in retrieval_nodes])\n",
    "        response = self.llm.complete(\n",
    "            qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "        # align to the response evaluation later\n",
    "        responseStructure = Myresponse(field1=str(response), field2=retrieval_nodes)\n",
    "        \n",
    "        return responseStructure\n",
    "\n",
    "synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "llm = Ollama(model=\"llama3.2\", temperature=0.6, request_timeout=300.0)\n",
    "\n",
    "query_engine = RAGStringQueryEngine(\n",
    "    retriever=hybrid_retriever_reranker_OR, \n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt\n",
    ")\n",
    "\n",
    "# query_text = \"What is the purpose of comprehensive data privacy policy?\"\n",
    "# query_text = \"where is the data storage locations?\"\n",
    "# query_text = \"What is the primary principle guiding [Company Name]'s business operations regarding personal data?\"\n",
    "# query_text = \"What is the foundational principle of [Company Name]'s business operations regarding personal data?\"\n",
    "# query_text = \"what is AI model?\"\n",
    "# query_text = \"Does the company allow three years of maternity leave?\"\n",
    "query_text = \"What is AI Ethics Policy? How do I follow the AI Ethics policy?\"\n",
    "response = query_engine.query(query_text)\n",
    "print(response.response)\n",
    "# # Print the top-matching nodes retrieval_nodes\n",
    "# print(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7e95d9b-590c-48dc-ab80-3c331d6066cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response evaluation, batch running\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    "    BatchEvalRunner\n",
    ")\n",
    "\n",
    "selected_items = list(qa_dataset.queries.items())\n",
    "\n",
    "# Convert back to dictionary (if needed)\n",
    "selected_queries = dict(selected_items)\n",
    "\n",
    "# Let's pick top 10 queries to do evaluation\n",
    "batch_eval_queries = selected_queries\n",
    "\n",
    "# pull gemma2:2b using Ollam pull gemma2:2b\n",
    "Evallm =  Ollama(model=\"phi3:mini\", request_timeout=300.0)\n",
    "# Evallm =  Ollama(model=\"gemma2:2b\", request_timeout=300.0)\n",
    "# Evallm =  llm\n",
    "faithfulness_gemma2 = FaithfulnessEvaluator(llm=Evallm)\n",
    "relevancy_gemma2 = RelevancyEvaluator(llm=Evallm)\n",
    "correctness_gemma2 = CorrectnessEvaluator(llm=Evallm)\n",
    "\n",
    "# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n",
    "runner = BatchEvalRunner(\n",
    "    # {\"faithfulness\": faithfulness_gemma2, \"relevancy\": relevancy_gemma2, 'correctness': correctness_gemma2},\n",
    "    {\"faithfulness\": faithfulness_gemma2, \"relevancy\": relevancy_gemma2},\n",
    "    # {\"faithfulness\": faithfulness_gemma2},\n",
    "    # {\"relevancy\": relevancy_gemma2},\n",
    "    workers=1, \n",
    ")\n",
    "\n",
    "# # Compute evaluation\n",
    "query_engine = RAGStringQueryEngine(\n",
    "    retriever=hybrid_retriever_reranker_OR, \n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt\n",
    ")\n",
    "\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine, queries=list(batch_eval_queries.values())\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "01026d21-f7ab-4a12-8bec-e24dfe7fdc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results['faithfulness'][1].passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35156355-2328-4b44-8946-5246b76c14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[key]\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result.passing:\n",
    "            correct += 1\n",
    "    score = correct / len(results)\n",
    "    print(f\"{key} Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d03f22fa-6979-4ef1-af32-427ed66a54fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness Score: 0.9382716049382716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9382716049382716"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = get_eval_results(\"faithfulness\", eval_results)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77a18c6d-67e8-4746-b9ad-32c67f3ab462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevancy Score: 0.8518518518518519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8518518518518519"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = get_eval_results(\"relevancy\", eval_results)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385cb08-e59e-4671-93de-05050137402e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
